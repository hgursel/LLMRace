services:
  llmrace-proxy:
    build: ./proxy
    container_name: llmrace-proxy
    ports:
      - "127.0.0.1:8000:8000"
    environment:
      - DATABASE_URL=sqlite:////data/llmrace.db
      - OLLAMA_DEFAULT_URL=http://host.docker.internal:11434
      - OPENAI_DEFAULT_URL=https://api.openai.com
      - ANTHROPIC_DEFAULT_URL=https://api.anthropic.com
      - OPENROUTER_DEFAULT_URL=https://openrouter.ai
      - OPENAI_COMPAT_DEFAULT_URL=http://host.docker.internal:1234
      - LLAMACPP_DEFAULT_URL=http://host.docker.internal:8080
      - CUSTOM_DEFAULT_URL=http://host.docker.internal:1234
      - LLMRACE_SECRET_KEY=${LLMRACE_SECRET_KEY:-llmrace-dev-secret-change-me}
      - OPENROUTER_HTTP_REFERER=${OPENROUTER_HTTP_REFERER:-}
      - OPENROUTER_X_TITLE=${OPENROUTER_X_TITLE:-LLMRace}
      - JAN_API_KEY=${JAN_API_KEY:-}
      - LMSTUDIO_API_KEY=${LMSTUDIO_API_KEY:-}
      - LLAMACPP_API_KEY=${LLAMACPP_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - llmrace_data:/data
    restart: unless-stopped

  llmrace-ui:
    build: ./ui
    container_name: llmrace-ui
    ports:
      - "127.0.0.1:3000:3000"
    depends_on:
      - llmrace-proxy
    restart: unless-stopped

volumes:
  llmrace_data:
